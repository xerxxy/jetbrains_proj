[
    {
        "prefix": "// Book.java\npackage com.example.bookapi;\n\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Book {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    p",
        "middle": "rivate String title;\n    private String author;\n\n    public Book() {\n    }\n",
        "suffix": "\n    public Book(String title, String author) {\n        this.title = title;\n        this.author = author;\n    }\n\n    // Getters and Setters\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getTitle() {\n        return title;\n    }\n\n    public void setTitle(String title) {\n        this.title = title;\n    }\n\n    public String getAuthor() {\n        return author;\n    }\n\n    public void setAuthor(String author) {\n        this.author = author;\n    }\n}"
    },
    {
        "prefix": "// BookController.java\npackage com.example.bookapi;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\nimport java.util.List;\nimport java.util.Optional;\n\n@RestController\n@RequestMapping(\"/api/books\")\npublic class BookController {\n\n    @Autowired\n    private BookRepository bookRepository;\n\n    // Get all books\n    @GetMapping\n    public List<Boo",
        "middle": "k> getAllBooks() {\n        return bookRepository.findAll();\n    }\n\n",
        "suffix": "    @GetMapping(\"/{id}\")\n    public ResponseEntity<Book> getBookById(@PathVariable Long id) {\n        Optional<Book> book = bookRepository.findById(id);\n        return book.map(ResponseEntity::ok)\n                   .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Add a new book\n    @PostMapping\n    public Book createBook(@RequestBody Book book) {\n        return bookRepository.save(book);\n    }\n\n    // Update an existing book by ID\n    @PutMapping(\"/{id}\")\n    public ResponseEntity<Book> updateBook(@PathVariable Long id, @RequestBody Book updatedBook) {\n        return bookRepository.findById(id)\n            .map(book -> {\n                book.setTitle(updatedBook.getTitle());\n                book.setAuthor(updatedBook.getAuthor());\n                return ResponseEntity.ok(bookRepository.save(book));\n            })\n            .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Delete a book by ID\n    @DeleteMapping(\"/{id}\")\n    public ResponseEntity<Void> deleteBook(@PathVariable Long id) {\n        if (bookRepository.existsById(id)) {\n            bookRepository.deleteById(id);\n            return ResponseEntity.ok().build();\n        } else {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}"
    },
    {
        "prefix": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 5\n#define COLS 5\n\n// Structure for a grid cell\ntypedef struct {\n    int x, y;\n} Cell;\n\n// Possible movements in 4 directions (up, down, left, right)\nint rowMoves[] = {-1, 1, 0, 0};\nint colMoves[] = {0, 0, -1, 1};\n\n// Function to perform BFS in a grid\nvoid bfs(int grid[ROWS][COLS], int startX, int startY) {\n    int visited[ROWS][COLS] = {0};\n    Cell queue[ROWS * COLS];\n    int front = 0, rear = 0;\n\n    // Starting point\n    queue[rear++] = (Cell){startX, startY};\n    visited[startX][startY] = 1;\n\n    printf(\"BFS Traversal starting from (%d, %d):\\n\", startX, startY);\n\n    while (front < rear) {\n        Cell current = queue[front++];\n        printf(\"(%d, %d) -> \", current.x, current.y);\n\n        // Explore neighbors\n        for (int i = 0; i < 4; i++) {\n            int newRow = current.x + rowMoves[i];\n            int newCol = current.y + colMoves[i];\n\n            if (newRow >= 0 && newRow < ROWS && newCol >= 0 && newCol < COLS &&\n                grid[newRow][newCol] == 1 && !visited[newRow][newCol]) {\n                visited[newRow][newCol] = 1;\n                queue[rear++] = (Cell){newRow, newCol};\n            }\n        }\n    }\n    printf(\"End of BFS\\n\");\n}\n\nint main() {\n    int grid[ROWS][COLS] = {\n        {1, 0,",
        "middle": " 1, 1, 1},\n        {1, 1, 0, 0, 1},\n        {0, 1, 1, 0, 1},\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 1, 1}\n    };\n",
        "suffix": "\n    // Start BFS from top-left corner (0, 0)\n    bfs(grid, 0, 0);\n    return 0;\n}"
    },
    {
        "prefix": "# iris_classification.py\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Load the Iris dataset\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define the column names\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n# Read the dataset\nirisdata = pd.read_csv(url, names=names)\n\n# Separate features (X) and target labels (y)\nX = irisdata.iloc[:, 0:4]\ny = irisdata.select_dtypes(include=[object])\n\n# Encode target labels as numeric values\nle = preprocessing.LabelEncoder()\ny = y.apply(le.fit_transform)\n\n# Split dataset into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\n# Scale features\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize and train MLP Classifier\nmlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\nmlp.fit(X_train, y_train.values.ravel())\n\n# Make predictions\npredictions = mlp.predict(X_test)\n\n# Print predictions\nprint(\"Predictions:\", predictions)\n\n# Evaluate model performance\nprint(\"Confusion Matrix:\")\nprint(confusion",
        "middle": "_matrix(y_test, predictions))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, predictions))\n",
        "suffix": ""
    },
    {
        "prefix": "// linked_list.c\n#include <stdio.h>\n#include <stdlib.h>\n\n// Define a node in the linked list\nstruct Node {\n    int data;\n    struct Node* next;\n};\n\n// Function to create a new node\nstruct Node* create_node(int data) {\n    struct Node* new_node = (struct Node*)malloc(sizeof(struct Node));\n    new_node->data = data;\n    new_node->next = NULL;\n    return new_node;\n}\n\n// Function to insert a node at the beginning of the list\nvoid insert_at_head(struct Node** head, int data) {\n    struct Node* new_node = create_node(data);\n    ne",
        "middle": "w_node->next = *head;\n    *head = new_node;\n}\n",
        "suffix": "\n// Function to display the linked list\nvoid display_list(struct Node* head) {\n    struct Node* current = head;\n    while (current != NULL) {\n        printf(\"%d -> \", current->data);\n        current = current->next;\n    }\n    printf(\"NULL\\n\");\n}\n\nint main() {\n    struct Node* head = NULL;\n\n    insert_at_head(&head, 10);\n    insert_at_head(&head, 20);\n    insert_at_head(&head, 30);\n\n    printf(\"Linked List:\\n\");\n    display_list(head);\n\n    return 0;\n}"
    },
    {
        "prefix": "// matrix_multiplication.c\n#include <stdio.h>\n\n#define SIZE 3\n\n// Function to multiply two matrices\nvoid multiply_matrices(i",
        "middle": "nt mat1[SIZE][SIZE], int mat2[SIZE][SIZE], int result[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n",
        "suffix": "            result[i][j] = 0;\n            for (int k = 0; k < SIZE; k++) {\n                result[i][j] += mat1[i][k] * mat2[k][j];\n            }\n        }\n    }\n}\n\nvoid print_matrix(int matrix[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            printf(\"%d \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nint main() {\n    int mat1[SIZE][SIZE] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n    int mat2[SIZE][SIZE] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n    int result[SIZE][SIZE];\n\n    multiply_matrices(mat1, mat2, result);\n\n    printf(\"Result of matrix multiplication:\\n\");\n    print_matrix(result);\n\n    return 0;\n}"
    },
    {
        "prefix": "import torch\nimport torch.nn as nn \nimport torch.optim as optim\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom code.models.circle.circle_net import CircleNet2_1, CircleNet2_2_1\n\n\ndef generate_data(num_points = 10000, seed = 42):\n    np.random.seed(seed)\n    X = np.random.uniform(-1.5, 1.5, (num_points, 2))\n    y = np.linalg.norm(X, axis = 1) <= 1\n    y = y.astype(int)\n    return X, y\n\ndef get_split(no_elements = 10000):\n    X,y = generate_data(no_elements)\n    print(\"This is y\", sum(y))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n    X_train = torch.tensor(X_train, dtype= torch.float32)\n    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n    return X_train, y_train, X_test, y_test\n\n\n\ndef train(model, criterion, optimizer, X_train, y_train, num_epochs = 1000):\n\n    for epoch in range(num_epochs):\n        model.train()\n        \n        outputs = model(X_train)\n\n        loss = criterion(outputs, y_train)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimiz",
        "middle": "er.step()\n\n",
        "suffix": "        # if (epoch + 1) % 100 == 0:\n        #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\ndef print_parameters(model):\n    for name, param in model.named_parameters():\n        print(f\"Parameter name: {name}\")\n        print(f\"Parameter size: {param.size()}\")\n        print(f\"Parameter values:\\n{param}\\n\")   \n           \ndef get_parameters_as_string(model):\n    param_str = \"\"\n    for name, param in model.named_parameters():\n        param_str += f\"{name}: {param.tolist()}; \"\n    return param_str\n\ndef plot_test_points_with_activations(X_test, test_outputs, y_test):\n    X_test_np = X_test.numpy()  \n    test_outputs_np = test_outputs.numpy().flatten()  # Model's predicted activations (output)\n    y_test_np = y_test.numpy().flatten()  # Actual labels for test data\n\n    plt.figure(figsize=(8, 6))\n\n    # Plot the points, colored by the sigmoid output (model's predicted activation)\n    plt.scatter(X_test_np[:, 0], X_test_np[:, 1], c=test_outputs_np, cmap='coolwarm', s=50, edgecolors='k')\n    \n    # Add color bar to show the activation values\n    plt.colorbar(label='Activation (Sigmoid Output)')\n    \n    # Set plot labels and title\n    plt.xlabel('X1 (Coordinate)')\n    plt.ylabel('X2 (Coordinate)')\n    plt.title('Test Points with Model Activations (Sigmoid Output)')\n    \n    # Show the plot\n    plt.show()\n    \ndef evaluate(model, X_test, y_test):\n\n    model.eval()\n    with torch.no_grad():\n\n        test_outputs = model(X_test)\n        \n        test_predictions = (test_outputs >= 0.5).float()  # Convert probabilities to binary 0/1 predictions\n\n        accuracy = (test_predictions.eq(y_test).sum() / float(y_test.shape[0])).item()\n        plot_test_points_with_activations(X_test, test_outputs,y_test)\n        return accuracy\n\n "
    },
    {
        "prefix": "import java.util.ArrayList;\nimport java.util.List;\n\npublic class Student {\n    private String name;\n    private int age;\n    private List<Integer> grades;\n    private int attendanceDays;\n\n    // Constructor\n    public Student(String name, int age) {\n        this.name = name;\n        this.age = age;\n        this.grades = new ArrayList<>();\n        this.attendanceDays = 0;\n    }\n\n    // Method to add a grade\n    public void addGrade(int grade) {\n        grades.add(grade);\n    }\n\n    // Method to calculate average grade\n    public double calculateAverage() {\n        if (grades.isEmpty()) return 0.0;\n        int total = grades.stream().mapToInt(Integer::intValue).sum();\n        return (double) total / grades.size();\n    }\n\n    // Method to update attendance\n    public void markAttendance() {\n        attendanceDays++;\n    }\n\n    // Method to display student information\n    public void displayInfo() {\n        System.out.println(\"Name: \" + name);\n        System.out.println(\"Age: \" + age);\n        System.out.println(\"Average Grade: \" + calculateAverage());\n        System.out.println(\"Attendance Days: \" + attendanceDays);\n    }\n\n    public static void main(String[] args) {\n        Student student = new Student(\"Alice\", 20);\n        student.addGrade(85);\n        student.a",
        "middle": "ddGrade(92);\n        student.addGrade(78);\n        student.markAttendance();\n        student.markAttendance();\n        student.displayInfo();\n    }\n",
        "suffix": "}"
    },
    {
        "prefix": "\ndef count_words(file_path):\n    \"\"\"Counts the words in a given text file.\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read()\n        words = text.split()\n        return len(words)\n    e",
        "middle": "xcept FileNotFoundError:\n        print(\"File not found!\")\n",
        "suffix": "        return None\n\ndef most_common_word(file_path):\n    \"\"\"Finds the most common word in a given text file.\"\"\"\n    from collections import Counter\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read().lower()\n        words = text.split()\n        word_counts = Counter(words)\n        return word_counts.most_common(1)[0]\n    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef main():\n    file_path = 'sample.txt'\n    print(f\"Total word count: {count_words(file_path)}\")\n    common_word, frequency = most_common_word(file_path)\n    print(f\"The most common word is '{common_word}' with a frequency of {frequency}.\")\n\nif __name__ == \"__main__\":\n    main()"
    },
    {
        "prefix": "// Book.java\npackage com.example.bookapi;\n\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Book {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    private String title;\n    private String author;\n\n    // Constructors\n    public Book() {\n    }\n\n    public Book(String title, String author) {\n        this.title = title;\n        this.author = author;\n    }\n\n    // Getters and Setters\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        thi",
        "middle": "s.id = id;\n    }\n",
        "suffix": "\n    public String getTitle() {\n        return title;\n    }\n\n    public void setTitle(String title) {\n        this.title = title;\n    }\n\n    public String getAuthor() {\n        return author;\n    }\n\n    public void setAuthor(String author) {\n        this.author = author;\n    }\n}"
    },
    {
        "prefix": "// BookController.java\npackage com.example.bookapi;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\nimport java.util.List;\nimport java.util.Optional;\n\n@RestController\n@RequestMapping(\"/api/books\")\npublic class BookController {\n\n    @Autowired\n    private BookRepository bookRepository;\n\n    // Get all books\n    @GetMapping\n    public List<Book> getAllBooks() {\n        return bookRepository.findAll();\n    }\n\n    // Get a book by ID\n    @GetMapping(\"/{id}\")\n    public ResponseEntity<Book> getBookById(@PathVariable Long id) {\n        Optional<Book> book = bookRepository.findById(id);\n        return book.map(ResponseEntity::ok)\n                   .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Add a new book\n    @PostMapping\n    public Book createBook(@RequestBody Book book) {\n        return bookRepository.save(book);\n    }\n\n    // Update an existing book by ID\n    @PutMapping(\"/{id}\")\n    public ResponseEntity<Book> updateBook(@PathVariable Long id, @RequestBody Book updatedBook) {\n        return bookRepository.findById(id)\n            .map(book -> {\n                book.setTitle(updatedBook.getTitle());\n                book.setAuthor(updatedBook.getAuthor());\n                return ResponseEntity.ok(bookRepository.save(book));\n            })\n            .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Delete a book by ID\n    @DeleteMapping(\"/{id}\")\n    public ResponseEntity<Void> deleteBook(@PathVariable Long id) {\n        if (bookRepository.existsById(id)) {\n            bookRepository.deleteById(id);\n            return ResponseEntity.ok().build();\n        } else {\n            return ResponseEntity.notFound().build();\n        ",
        "middle": "}\n    }\n}\n",
        "suffix": ""
    },
    {
        "prefix": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 5\n#define COLS 5\n\n// Structure for a grid cell\ntypedef struct {\n    int x, y;\n} Cell;\n\n// Possible movements in 4 directions (up, down, left, right)\nint rowMoves[] = {-1, 1, 0, 0};\nint colMoves[] = {0, 0, -1, 1};\n\n// Function to perform BFS in a grid\nvoid bfs(int grid[ROWS][COLS], int startX, int startY) {\n    int visited[ROWS][COLS] = {0};\n    Cell queue[ROWS * COLS];\n    int front = 0, rear = 0;\n\n    // Starting point\n    queue[rear++] = (Cell){startX, startY};\n    visited[startX][startY] = 1;\n\n    printf(\"BFS Traversal starting from (%d, %d):\\n\", startX, startY);\n\n    while (front < rear) {\n        Cell cur",
        "middle": "rent = queue[front++];\n        printf(\"(%d, %d) -> \", current.x, current.y);\n",
        "suffix": "\n        // Explore neighbors\n        for (int i = 0; i < 4; i++) {\n            int newRow = current.x + rowMoves[i];\n            int newCol = current.y + colMoves[i];\n\n            if (newRow >= 0 && newRow < ROWS && newCol >= 0 && newCol < COLS &&\n                grid[newRow][newCol] == 1 && !visited[newRow][newCol]) {\n                visited[newRow][newCol] = 1;\n                queue[rear++] = (Cell){newRow, newCol};\n            }\n        }\n    }\n    printf(\"End of BFS\\n\");\n}\n\nint main() {\n    int grid[ROWS][COLS] = {\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 0, 1},\n        {0, 1, 1, 0, 1},\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 1, 1}\n    };\n\n    // Start BFS from top-left corner (0, 0)\n    bfs(grid, 0, 0);\n    return 0;\n}"
    },
    {
        "prefix": "# iris_classification.py\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Load the Iris dataset\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define the column names\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n# Read the dataset\nirisdata = pd.read_csv(url, names=names)\n\n# Separate features (X) and target labels (y)\nX = irisdata.iloc[:, 0:4]\ny = irisdata.select_dtypes(include=[object])\n\n# Encode target labels as numeric values\nle = preprocessing.LabelEncoder()\ny = y.apply(le.fit_transform)\n\n# Split dataset into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\n# Scale features\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize and train MLP Classifier\nmlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\nmlp.fit(X_train, y_train.values.ravel())\n\n# Make predictions\npredictions = mlp.predict(X_test)\n\n# Print predictions\nprint(\"Predictions:\", predictions)\n\n# Evaluate model performance\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\npri",
        "middle": "nt(\"\\nClassification Report:\")\nprint(classification_report(y_test, predictions))\n",
        "suffix": ""
    },
    {
        "prefix": "// linked_list.c\n#include <stdio.h>\n#include <stdlib.h>\n\n// Define a node in the linked list\nstruct Node {\n    int data;\n    struct Node* next;\n};\n\n// Function to create a new node\nstruct Node* create_node(int data) {\n    struct Node* new_node = (struct Node*)malloc(sizeof(struct Node));\n    new_node->data = data;\n    new_node->next = NULL;\n    return new_node;\n}\n\n// Function to insert a node at the beginning of the list\nvoid insert_at_head(struct Node** head, int data) {\n    struct Node* new_node = create_node(data);\n    new_node->next = *head;\n    *head = new_node;\n}\n\n// Function to display the linked list\nvoid display_list(struct Node* head) {\n    struct Node* current = head;\n    while (current != NULL) {\n        printf(\"%d -> \", current->data);\n        current = current->next;\n    }\n    printf(\"NULL\\n\");\n}\n\nint main() {\n    struct Node* head = NULL;\n\n    insert_at_head(&head, 10);\n    insert_at_head(&head, 20);\n    insert_at_head(&head, 30);\n\n    printf(\"Linked List:\\n\");\n    disp",
        "middle": "lay_list(head);\n\n    return 0;\n",
        "suffix": "}"
    },
    {
        "prefix": "// matrix_multiplication.c\n#include <stdio.h>\n\n#define SIZE 3\n\n// Function to multiply two matrices\nvoid multiply_matrices(int mat1[SIZE][SIZE], int mat2[SIZE][SIZE], int result[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            result[i][j] = 0;\n            for (int k = 0; k < SIZE; k++) {\n                result[i][j] += mat1[i][k] * mat2[k][j];\n            }\n        }\n    }\n",
        "middle": "}\n\nvoid print_matrix(int matrix[SIZE][SIZE]) {\n",
        "suffix": "    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            printf(\"%d \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nint main() {\n    int mat1[SIZE][SIZE] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n    int mat2[SIZE][SIZE] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n    int result[SIZE][SIZE];\n\n    multiply_matrices(mat1, mat2, result);\n\n    printf(\"Result of matrix multiplication:\\n\");\n    print_matrix(result);\n\n    return 0;\n}"
    },
    {
        "prefix": "import torch\nimport torch.nn as nn \nimport torch.optim as optim\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom code.models.circle.circle_net import CircleNet2_1, CircleNet2_2_1\n\n\ndef generate_data(num_points = 10000, seed = 42):\n    np.random.seed(seed)\n    X = np.random.uniform(-1.5, 1.5, (num_points, 2))\n    y = np.linalg.norm(X, axis = 1) <= 1\n    y = y.astype(int)\n    return X, y\n\ndef get_split(no_elements = 10000):\n    X,y =",
        "middle": " generate_data(no_elements)\n    print(\"This is y\", sum(y))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
        "suffix": "    X_train = torch.tensor(X_train, dtype= torch.float32)\n    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n    return X_train, y_train, X_test, y_test\n\n\n\ndef train(model, criterion, optimizer, X_train, y_train, num_epochs = 1000):\n\n    for epoch in range(num_epochs):\n        model.train()\n        \n        outputs = model(X_train)\n\n        loss = criterion(outputs, y_train)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n\n        # if (epoch + 1) % 100 == 0:\n        #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\ndef print_parameters(model):\n    for name, param in model.named_parameters():\n        print(f\"Parameter name: {name}\")\n        print(f\"Parameter size: {param.size()}\")\n        print(f\"Parameter values:\\n{param}\\n\")   \n           \ndef get_parameters_as_string(model):\n    param_str = \"\"\n    for name, param in model.named_parameters():\n        param_str += f\"{name}: {param.tolist()}; \"\n    return param_str\n\ndef plot_test_points_with_activations(X_test, test_outputs, y_test):\n    X_test_np = X_test.numpy()  \n    test_outputs_np = test_outputs.numpy().flatten()  # Model's predicted activations (output)\n    y_test_np = y_test.numpy().flatten()  # Actual labels for test data\n\n    plt.figure(figsize=(8, 6))\n\n    # Plot the points, colored by the sigmoid output (model's predicted activation)\n    plt.scatter(X_test_np[:, 0], X_test_np[:, 1], c=test_outputs_np, cmap='coolwarm', s=50, edgecolors='k')\n    \n    # Add color bar to show the activation values\n    plt.colorbar(label='Activation (Sigmoid Output)')\n    \n    # Set plot labels and title\n    plt.xlabel('X1 (Coordinate)')\n    plt.ylabel('X2 (Coordinate)')\n    plt.title('Test Points with Model Activations (Sigmoid Output)')\n    \n    # Show the plot\n    plt.show()\n    \ndef evaluate(model, X_test, y_test):\n\n    model.eval()\n    with torch.no_grad():\n\n        test_outputs = model(X_test)\n        \n        test_predictions = (test_outputs >= 0.5).float()  # Convert probabilities to binary 0/1 predictions\n\n        accuracy = (test_predictions.eq(y_test).sum() / float(y_test.shape[0])).item()\n        plot_test_points_with_activations(X_test, test_outputs,y_test)\n        return accuracy\n\n "
    },
    {
        "prefix": "import java.util.ArrayList;\nimport java.util.List;\n\npublic class Student {\n    private String name;\n    private int age;\n    private List<Integer> grades;\n    private int attendanceDays;\n\n    // Constructor\n    public Student(String name, int age) {\n        this.name = name;\n        this.age = age;\n        this.grades = new ArrayList<>();\n        this.attendanceDays = 0;\n    }\n\n    // Method to add a grade\n    public void addGrade(int grade) {\n        grades.add(grade);\n    }\n\n    // Method to calculate average grade\n    public double calculateAverage() {\n        if (grades.isEmpty()) return 0.0;\n        int total = grades.stream().mapToInt(Integer::intValue).sum();\n        return (double) total / grades.size();\n    }\n\n    // Method to update attendance\n    public void markAttendance() {\n        attendanceDays++;\n    }\n\n    // Method to display student information\n    public void displayInfo() {\n        System.out.println(\"Name: \" + name);\n        System.out.println(\"Age: \" + age);\n        System.out.println(\"Average Grade: \" + calculateAverage());\n        System.out.println(\"Attendance Days: \" + attendanceDays);\n    }\n\n    public static void main(String[] args) {\n        Student student = new Student(\"Alice\", 20);\n        student.addGrade(85);\n        student.addGrade(92);\n        student.addGrade(78);\n        student.markAttendance();\n        student.markAttendance();\n        student",
        "middle": ".displayInfo();\n    }\n}\n",
        "suffix": ""
    },
    {
        "prefix": "\ndef count_words(file_path):\n    \"\"\"Counts the words in a given text file.\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read()\n        words = text.split()\n        return len(words)\n    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef most_common_word(file_path):\n    \"\"\"Finds the most common word in a given text file.\"\"\"\n    from collections import Counter\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read().lower()\n        words = text.split()\n        word_counts = Counter(words)\n        return word_counts.most_common(1)[0]\n    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef main():\n    file_path = 'sample.txt'\n    print(f\"Total word count: {count_words(file_path)}\")\n    common_word, fre",
        "middle": "quency = most_common_word(file_path)\n    print(f\"The most common word is '{common_word}' with a frequency of {frequency}.\")\n\nif __name__ == \"__main__\":\n    main()\n",
        "suffix": ""
    },
    {
        "prefix": "// Book.java\npackage com.example.bookapi;\n\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Book {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    privat",
        "middle": "e Long id;\n    private String title;\n    private String author;\n\n",
        "suffix": "    public Book() {\n    }\n\n    public Book(String title, String author) {\n        this.title = title;\n        this.author = author;\n    }\n\n    // Getters and Setters\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getTitle() {\n        return title;\n    }\n\n    public void setTitle(String title) {\n        this.title = title;\n    }\n\n    public String getAuthor() {\n        return author;\n    }\n\n    public void setAuthor(String author) {\n        this.author = author;\n    }\n}"
    },
    {
        "prefix": "// BookController.java\npackage com.example.bookapi;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport ",
        "middle": "org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\nimport java.util.List;\nimport java.util.Optional;\n\n",
        "suffix": "@RestController\n@RequestMapping(\"/api/books\")\npublic class BookController {\n\n    @Autowired\n    private BookRepository bookRepository;\n\n    // Get all books\n    @GetMapping\n    public List<Book> getAllBooks() {\n        return bookRepository.findAll();\n    }\n\n    // Get a book by ID\n    @GetMapping(\"/{id}\")\n    public ResponseEntity<Book> getBookById(@PathVariable Long id) {\n        Optional<Book> book = bookRepository.findById(id);\n        return book.map(ResponseEntity::ok)\n                   .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Add a new book\n    @PostMapping\n    public Book createBook(@RequestBody Book book) {\n        return bookRepository.save(book);\n    }\n\n    // Update an existing book by ID\n    @PutMapping(\"/{id}\")\n    public ResponseEntity<Book> updateBook(@PathVariable Long id, @RequestBody Book updatedBook) {\n        return bookRepository.findById(id)\n            .map(book -> {\n                book.setTitle(updatedBook.getTitle());\n                book.setAuthor(updatedBook.getAuthor());\n                return ResponseEntity.ok(bookRepository.save(book));\n            })\n            .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Delete a book by ID\n    @DeleteMapping(\"/{id}\")\n    public ResponseEntity<Void> deleteBook(@PathVariable Long id) {\n        if (bookRepository.existsById(id)) {\n            bookRepository.deleteById(id);\n            return ResponseEntity.ok().build();\n        } else {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}"
    },
    {
        "prefix": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 5\n#define COLS 5\n\n// Structure for a grid cell\ntypedef struct {\n    int x, y;\n} Cell;\n\n// Possible movements in 4 directions (up, down, left, right)\nint rowMoves[] = {-1, 1, 0, 0};\nint colMoves[] = {0, 0, -1, 1};\n\n// Function to perform BFS in a grid\nvoid bfs(int grid[ROWS][COLS], int startX, int startY) {\n    int visited[ROWS][COLS] = {0};\n    Cell queue[ROWS * COLS];\n    int front = 0, rear = 0;\n\n    // Starting point\n    queue[rear++] = (Cell){startX, startY};\n    visited[startX][startY] = 1;\n\n    printf(\"BFS Traversal starting from (%d, %d):\\n\", startX, startY);\n\n    while (front < rear) {\n        Cell current = queue[front++];\n        printf(\"(%d, %d) -> \", current.x, current.y);\n\n        // Explore neighbors\n        for (int i = 0; i < 4; i++) {\n            int newRow = current.x + rowMoves[i];\n            int newCol = current.y + colMoves[i];\n\n            if (newRow >= 0 && newRow < ROWS && newCol >= 0 && newCol < COLS &&\n                grid[newRow][newCol] == 1 && !visited[newRow][newCol]) {\n                visited[newRow][newCol] = 1;\n                queue[rear++] = (Cell){newRow, newCol};\n            }\n        }\n    }\n    pr",
        "middle": "intf(\"End of BFS\\n\");\n}\n\nint main() {\n    int grid[ROWS][COLS] = {\n",
        "suffix": "        {1, 0, 1, 1, 1},\n        {1, 1, 0, 0, 1},\n        {0, 1, 1, 0, 1},\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 1, 1}\n    };\n\n    // Start BFS from top-left corner (0, 0)\n    bfs(grid, 0, 0);\n    return 0;\n}"
    },
    {
        "prefix": "# iris_classification.py\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Load the Iris dataset\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define the column names\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n# Read the dataset\nirisdata = pd.read_csv(url, names=names)\n\n# Separate features (X) and target labels (y)\nX = irisdata.iloc[:, 0:4]\ny = irisdata.select_dtypes(include=[object])\n\n# Encode target labels as numeric values\nle = preprocessing.LabelEncoder()\ny = y.apply(le.fit_transform)\n\n# Split dataset into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\n# Scale features\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize and train MLP Classifier\nmlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\nmlp.fit(X_train, y_train.values.ravel())\n\n# Make predictions\npredictions = mlp.predict(X_test)\n\n# Print predictions\nprin",
        "middle": "t(\"Predictions:\", predictions)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\nprint(\"\\nClassification Report:\")\n",
        "suffix": "print(classification_report(y_test, predictions))"
    },
    {
        "prefix": "// linked_list.c\n#include <stdio.h>\n#include <stdlib.h>\n\n// Define a node in the linked list\nstruct Node {\n    int data;\n    struct Node* next;\n};\n\n// Function to create a new node\nstruct Node* create_node(int data) {\n    struct Node* new_node = (struct Node*)malloc(sizeof(struct Node));\n    new_node->data = data;\n    new_node->next = NULL;\n    return new_node;\n}\n\n// Function to insert a node at the beginning of the list\nvoid insert_at_head(struct Node** head, int data) {\n    struct Node* new_node = create_node(data);\n    ",
        "middle": "new_node->next = *head;\n    *head = new_node;\n}\n\n",
        "suffix": "// Function to display the linked list\nvoid display_list(struct Node* head) {\n    struct Node* current = head;\n    while (current != NULL) {\n        printf(\"%d -> \", current->data);\n        current = current->next;\n    }\n    printf(\"NULL\\n\");\n}\n\nint main() {\n    struct Node* head = NULL;\n\n    insert_at_head(&head, 10);\n    insert_at_head(&head, 20);\n    insert_at_head(&head, 30);\n\n    printf(\"Linked List:\\n\");\n    display_list(head);\n\n    return 0;\n}"
    },
    {
        "prefix": "// matrix_multiplication.c\n#include <stdio.h>\n\n#define SIZE 3\n\n// Function to multiply two matrices\nvoid multiply_matrices(int mat1[SIZE][SIZE], int mat2[SIZE][SIZE], int result[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            result[i][j] = 0;\n            for (int k = 0; k < SIZE; k++) {\n                result[i][j] += mat1[i][k] * mat2[k][j];\n            }\n        }\n    }\n}\n\nvoid print_matrix(int matrix[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            printf(\"%d \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    ",
        "middle": "}\n}\n\nint main() {\n    int mat1[SIZE][SIZE] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n    int mat2[SIZE][SIZE] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "suffix": "    int result[SIZE][SIZE];\n\n    multiply_matrices(mat1, mat2, result);\n\n    printf(\"Result of matrix multiplication:\\n\");\n    print_matrix(result);\n\n    return 0;\n}"
    },
    {
        "prefix": "import torch\nimport torch.nn as nn \nimport torch.optim as optim\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom code.models.circle.circle_net import CircleNet2_1, CircleNet2_2_1\n\n\ndef generate_data(num_points = 10000, seed = 42):\n    np.random.seed(seed)\n    X = np.random.uniform(-1.5, 1.5, (num_points, 2))\n    y = np.linalg.norm(X, axis = 1) <= 1\n    y = y.astype(int)\n    return X, y\n\ndef get_split(no_elements = 10000):\n    X,y = generate_data(no_elements)\n    print(\"This is y\", sum(y))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n    X_train = torch.tensor(X_train, dtype= torch.float32)\n    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n    return X_train, y_train, X_test, y_test\n\n\n\ndef train(model, criterion, optimizer, X_train, y_train, num_epochs = 1000):\n\n    for epoch in range(num_epochs):\n        model.train()\n        \n        outputs = model(X_train)\n\n        loss = criterion(outputs, y_train)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n\n        # if (epoch + 1) % 100 == 0:\n        #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\ndef print_parameters(model):\n    for name, p",
        "middle": "aram in model.named_parameters():\n        print(f\"Parameter name: {name}\")\n        print(f\"Parameter size: {param.size()}\")\n",
        "suffix": "        print(f\"Parameter values:\\n{param}\\n\")   \n           \ndef get_parameters_as_string(model):\n    param_str = \"\"\n    for name, param in model.named_parameters():\n        param_str += f\"{name}: {param.tolist()}; \"\n    return param_str\n\ndef plot_test_points_with_activations(X_test, test_outputs, y_test):\n    X_test_np = X_test.numpy()  \n    test_outputs_np = test_outputs.numpy().flatten()  # Model's predicted activations (output)\n    y_test_np = y_test.numpy().flatten()  # Actual labels for test data\n\n    plt.figure(figsize=(8, 6))\n\n    # Plot the points, colored by the sigmoid output (model's predicted activation)\n    plt.scatter(X_test_np[:, 0], X_test_np[:, 1], c=test_outputs_np, cmap='coolwarm', s=50, edgecolors='k')\n    \n    # Add color bar to show the activation values\n    plt.colorbar(label='Activation (Sigmoid Output)')\n    \n    # Set plot labels and title\n    plt.xlabel('X1 (Coordinate)')\n    plt.ylabel('X2 (Coordinate)')\n    plt.title('Test Points with Model Activations (Sigmoid Output)')\n    \n    # Show the plot\n    plt.show()\n    \ndef evaluate(model, X_test, y_test):\n\n    model.eval()\n    with torch.no_grad():\n\n        test_outputs = model(X_test)\n        \n        test_predictions = (test_outputs >= 0.5).float()  # Convert probabilities to binary 0/1 predictions\n\n        accuracy = (test_predictions.eq(y_test).sum() / float(y_test.shape[0])).item()\n        plot_test_points_with_activations(X_test, test_outputs,y_test)\n        return accuracy\n\n "
    },
    {
        "prefix": "import java.util.ArrayList;\nimport java.util.List;\n\npublic class Student {\n    private String name;\n    private int age;\n    private List<Integer> grades;\n    private int attendanceDays;\n\n    // Constructor\n    public Student(String name, int age) {\n        this.name = name;\n        this.age = age;\n        this.grades = new ArrayList<>();\n        this.attendanceDays = 0;\n    }\n\n    // Method to add a grade\n    public void addGrade(int grade) {\n        grades.add(grade);\n    }\n\n    // Method to calculate average grade\n    public double calculateAverage() {\n        if (grades.isEmpty()) return 0.0;\n        int total = grades.stream().mapToInt(Integer::intValue).sum();\n        return (double) total / grades.size();\n    }\n\n    // Method to update attendance\n    public void markAttendance() {\n        attendanceDays++;\n    }\n\n    // Method to display student information\n    public void d",
        "middle": "isplayInfo() {\n        System.out.println(\"Name: \" + name);\n        System.out.println(\"Age: \" + age);\n        System.out.println(\"Average Grade: \" + calculateAverage());\n",
        "suffix": "        System.out.println(\"Attendance Days: \" + attendanceDays);\n    }\n\n    public static void main(String[] args) {\n        Student student = new Student(\"Alice\", 20);\n        student.addGrade(85);\n        student.addGrade(92);\n        student.addGrade(78);\n        student.markAttendance();\n        student.markAttendance();\n        student.displayInfo();\n    }\n}"
    },
    {
        "prefix": "\ndef count_words(file_path):\n    \"\"\"Counts the words in a given text file.\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read()\n        words = text.split()\n        return len(words)\n    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef most_common_word(file_path):\n    \"\"\"Finds the most common word in a given text file.\"\"\"\n    from collections import Counter\n    try:\n        with ",
        "middle": "open(file_path, 'r') as file:\n            text = file.read().lower()\n        words = text.split()\n        word_counts = Counter(words)\n        return word_counts.most_common(1)[0]\n",
        "suffix": "    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef main():\n    file_path = 'sample.txt'\n    print(f\"Total word count: {count_words(file_path)}\")\n    common_word, frequency = most_common_word(file_path)\n    print(f\"The most common word is '{common_word}' with a frequency of {frequency}.\")\n\nif __name__ == \"__main__\":\n    main()"
    },
    {
        "prefix": "// Book.java\npackage com.example.bookapi;\n\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Book {\n    ",
        "middle": "@Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
        "suffix": "    private Long id;\n    private String title;\n    private String author;\n\n    // Constructors\n    public Book() {\n    }\n\n    public Book(String title, String author) {\n        this.title = title;\n        this.author = author;\n    }\n\n    // Getters and Setters\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getTitle() {\n        return title;\n    }\n\n    public void setTitle(String title) {\n        this.title = title;\n    }\n\n    public String getAuthor() {\n        return author;\n    }\n\n    public void setAuthor(String author) {\n        this.author = author;\n    }\n}"
    },
    {
        "prefix": "// BookController.java\npackage com.example.bookapi;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.*;\n\nimport ",
        "middle": "java.util.List;\nimport java.util.Optional;\n\n@RestController\n",
        "suffix": "@RequestMapping(\"/api/books\")\npublic class BookController {\n\n    @Autowired\n    private BookRepository bookRepository;\n\n    // Get all books\n    @GetMapping\n    public List<Book> getAllBooks() {\n        return bookRepository.findAll();\n    }\n\n    // Get a book by ID\n    @GetMapping(\"/{id}\")\n    public ResponseEntity<Book> getBookById(@PathVariable Long id) {\n        Optional<Book> book = bookRepository.findById(id);\n        return book.map(ResponseEntity::ok)\n                   .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Add a new book\n    @PostMapping\n    public Book createBook(@RequestBody Book book) {\n        return bookRepository.save(book);\n    }\n\n    // Update an existing book by ID\n    @PutMapping(\"/{id}\")\n    public ResponseEntity<Book> updateBook(@PathVariable Long id, @RequestBody Book updatedBook) {\n        return bookRepository.findById(id)\n            .map(book -> {\n                book.setTitle(updatedBook.getTitle());\n                book.setAuthor(updatedBook.getAuthor());\n                return ResponseEntity.ok(bookRepository.save(book));\n            })\n            .orElseGet(() -> ResponseEntity.notFound().build());\n    }\n\n    // Delete a book by ID\n    @DeleteMapping(\"/{id}\")\n    public ResponseEntity<Void> deleteBook(@PathVariable Long id) {\n        if (bookRepository.existsById(id)) {\n            bookRepository.deleteById(id);\n            return ResponseEntity.ok().build();\n        } else {\n            return ResponseEntity.notFound().build();\n        }\n    }\n}"
    },
    {
        "prefix": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 5\n#define COLS 5\n\n// Structure for a grid cell\ntypedef struct {\n    int x, y;\n} Cell;\n\n// Possible movements in 4 directions (up, down, left, right)\nint rowMoves[] = {-1, 1, 0, 0};\nint colMoves[] = {0, 0, -1, 1};\n\n// Function to perform BFS in a grid\nvoid bfs(int grid[ROWS][COLS], int startX, int startY) {\n    int visited[ROWS][COLS] = {0};\n    Cell queue[ROWS * COLS];\n    int front = 0, rear = 0;\n\n    // Starting point\n    queue[rear++] = (Cell){startX, startY};\n    visited[startX][startY] = 1;\n\n    printf(\"BFS Traversal starting from (%d, %d):\\n\", startX, startY);\n\n    while (front < rear) {\n        Cell current = queue[front++];\n        printf(\"(%d, %d) -> \", current.x, current.y);\n\n        // Explore neighbors\n        for (int i = 0; i < 4; i++) {\n            int newRow = current.x + rowMoves[i];\n            in",
        "middle": "t newCol = current.y + colMoves[i];\n\n            if (newRow >= 0 && newRow < ROWS && newCol >= 0 && newCol < COLS &&\n",
        "suffix": "                grid[newRow][newCol] == 1 && !visited[newRow][newCol]) {\n                visited[newRow][newCol] = 1;\n                queue[rear++] = (Cell){newRow, newCol};\n            }\n        }\n    }\n    printf(\"End of BFS\\n\");\n}\n\nint main() {\n    int grid[ROWS][COLS] = {\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 0, 1},\n        {0, 1, 1, 0, 1},\n        {1, 0, 1, 1, 1},\n        {1, 1, 0, 1, 1}\n    };\n\n    // Start BFS from top-left corner (0, 0)\n    bfs(grid, 0, 0);\n    return 0;\n}"
    },
    {
        "prefix": "# iris_classification.py\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Load the Iris dataset\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n# Define the column names\nnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n# Read the dataset\nirisdata = pd.read_csv(url, names=names)\n\n# Separate features (X) and target labels (y)\nX = irisdata.iloc[:, 0:4]\ny = irisdata.select_dtypes(include=[object])\n\n# Encode target labels as numeric values\nle = preprocessing.LabelEncoder()\ny = y.apply(le.fit_transform)\n\n# Split dataset into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\n# Scale features\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.",
        "middle": "transform(X_train)\nX_test = scaler.transform(X_test)\n\nmlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\nmlp.fit(X_train, y_train.values.ravel())\n",
        "suffix": "\n# Make predictions\npredictions = mlp.predict(X_test)\n\n# Print predictions\nprint(\"Predictions:\", predictions)\n\n# Evaluate model performance\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, predictions))"
    },
    {
        "prefix": "// linked_list.c\n#include <stdio.h>\n#include <stdlib.h>\n\n// Define a node in the linked list\nstruct Node {\n    int data;\n    struct Node* next;\n}",
        "middle": ";\n\nstruct Node* create_node(int data) {\n    struct Node* new_node = (struct Node*)malloc(sizeof(struct Node));\n    new_node->data = data;\n",
        "suffix": "    new_node->next = NULL;\n    return new_node;\n}\n\n// Function to insert a node at the beginning of the list\nvoid insert_at_head(struct Node** head, int data) {\n    struct Node* new_node = create_node(data);\n    new_node->next = *head;\n    *head = new_node;\n}\n\n// Function to display the linked list\nvoid display_list(struct Node* head) {\n    struct Node* current = head;\n    while (current != NULL) {\n        printf(\"%d -> \", current->data);\n        current = current->next;\n    }\n    printf(\"NULL\\n\");\n}\n\nint main() {\n    struct Node* head = NULL;\n\n    insert_at_head(&head, 10);\n    insert_at_head(&head, 20);\n    insert_at_head(&head, 30);\n\n    printf(\"Linked List:\\n\");\n    display_list(head);\n\n    return 0;\n}"
    },
    {
        "prefix": "// matrix_multiplication.c\n#include <stdio.h>\n\n#define SIZE 3\n\n// Function to multiply two matrices\nvoid multiply_matrices(int mat1[SIZE][SIZE], int mat2[SIZE][SIZE], int result[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            result[i][j] = 0;\n            for (int k = 0; k < SIZE; k++) {\n                re",
        "middle": "sult[i][j] += mat1[i][k] * mat2[k][j];\n            }\n",
        "suffix": "        }\n    }\n}\n\nvoid print_matrix(int matrix[SIZE][SIZE]) {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            printf(\"%d \", matrix[i][j]);\n        }\n        printf(\"\\n\");\n    }\n}\n\nint main() {\n    int mat1[SIZE][SIZE] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n    int mat2[SIZE][SIZE] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n    int result[SIZE][SIZE];\n\n    multiply_matrices(mat1, mat2, result);\n\n    printf(\"Result of matrix multiplication:\\n\");\n    print_matrix(result);\n\n    return 0;\n}"
    },
    {
        "prefix": "import torch\nimport torch.nn as nn \nimport torch.optim as optim\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom code.models.circle.circle_net import CircleNet2_1, CircleNet2_2_1\n\n\ndef generate_data(num_points = 10000, seed = 42):\n    np.random.seed(seed)\n    X = np.random.uniform(-1.5, 1.5, (num_points, 2))\n    y = np.linalg.norm(X, axis = 1) <= 1\n    y = y.astype(int)\n    return X, y\n\ndef get_split(no_elements = 10000):\n    X,y = generate_data(no_elements)\n    print(\"This is y\", sum(y))\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n    X_train = torch.tensor(X_train, dtype= torch.float32)\n    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n    return X_train, y_train, X_test, y_test\n\n\n\ndef train(model, criterion, optimizer, X_train, y_train, num_epochs = 1000):\n\n    for epoch in range(num_epochs):\n        model.train()\n        \n        outputs = model(X_train)\n\n        loss = criterion(outputs, y_train)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n\n        # if (epoch + 1) % 100 == 0:\n        #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\ndef print_parameters(model):\n    for name, param in model.named_parameters():\n        print(f\"Parameter name: {name}\")\n        print(f\"Parameter size: {param.size()}\")\n        print(f\"Parameter values:\\n{param}\\n\")   \n           \ndef get_parameters_as_string(model):\n    param_str = \"\"\n    for name, param in model.named_parameters():\n        param_str += f\"{name}: {param.tolist()}; \"\n    return param_str\n\ndef plot_test_points_with_activations(X_test, test_outputs, y_test):\n    X_te",
        "middle": "st_np = X_test.numpy()  \n    test_outputs_np = test_outputs.numpy().flatten()  # Model's predicted activations (output)\n    y_test_np = y_test.numpy().flatten()  # Actual labels for test data\n",
        "suffix": "\n    plt.figure(figsize=(8, 6))\n\n    # Plot the points, colored by the sigmoid output (model's predicted activation)\n    plt.scatter(X_test_np[:, 0], X_test_np[:, 1], c=test_outputs_np, cmap='coolwarm', s=50, edgecolors='k')\n    \n    # Add color bar to show the activation values\n    plt.colorbar(label='Activation (Sigmoid Output)')\n    \n    # Set plot labels and title\n    plt.xlabel('X1 (Coordinate)')\n    plt.ylabel('X2 (Coordinate)')\n    plt.title('Test Points with Model Activations (Sigmoid Output)')\n    \n    # Show the plot\n    plt.show()\n    \ndef evaluate(model, X_test, y_test):\n\n    model.eval()\n    with torch.no_grad():\n\n        test_outputs = model(X_test)\n        \n        test_predictions = (test_outputs >= 0.5).float()  # Convert probabilities to binary 0/1 predictions\n\n        accuracy = (test_predictions.eq(y_test).sum() / float(y_test.shape[0])).item()\n        plot_test_points_with_activations(X_test, test_outputs,y_test)\n        return accuracy\n\n "
    },
    {
        "prefix": "import java.util.ArrayList;\nimport java.util.List;\n\npublic class Student {\n    private String name;\n    private int age;\n    private List<Integer> grades;\n    private",
        "middle": " int attendanceDays;\n\n",
        "suffix": "    public Student(String name, int age) {\n        this.name = name;\n        this.age = age;\n        this.grades = new ArrayList<>();\n        this.attendanceDays = 0;\n    }\n\n    // Method to add a grade\n    public void addGrade(int grade) {\n        grades.add(grade);\n    }\n\n    // Method to calculate average grade\n    public double calculateAverage() {\n        if (grades.isEmpty()) return 0.0;\n        int total = grades.stream().mapToInt(Integer::intValue).sum();\n        return (double) total / grades.size();\n    }\n\n    // Method to update attendance\n    public void markAttendance() {\n        attendanceDays++;\n    }\n\n    // Method to display student information\n    public void displayInfo() {\n        System.out.println(\"Name: \" + name);\n        System.out.println(\"Age: \" + age);\n        System.out.println(\"Average Grade: \" + calculateAverage());\n        System.out.println(\"Attendance Days: \" + attendanceDays);\n    }\n\n    public static void main(String[] args) {\n        Student student = new Student(\"Alice\", 20);\n        student.addGrade(85);\n        student.addGrade(92);\n        student.addGrade(78);\n        student.markAttendance();\n        student.markAttendance();\n        student.displayInfo();\n    }\n}"
    },
    {
        "prefix": "\ndef count_words(file_path):\n    \"\"\"Counts the words in a given text file.\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            text = file.read()\n        words = text.split()\n        return len(words)\n    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef most_common_word(file_path):\n    \"\"\"Finds the most common word in a given text file.\"\"\"\n    from collections import Counter\n    try:\n        with open(file_path, 'r') as file:\n            text = fil",
        "middle": "e.read().lower()\n        words = text.split()\n        word_counts = Counter(words)\n        return word_counts.most_common(1)[0]\n",
        "suffix": "    except FileNotFoundError:\n        print(\"File not found!\")\n        return None\n\ndef main():\n    file_path = 'sample.txt'\n    print(f\"Total word count: {count_words(file_path)}\")\n    common_word, frequency = most_common_word(file_path)\n    print(f\"The most common word is '{common_word}' with a frequency of {frequency}.\")\n\nif __name__ == \"__main__\":\n    main()"
    }
]